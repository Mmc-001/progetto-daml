{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aaed1-c8f1-4378-a802-a949e502b649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#installation of tensorflow_datasets and Collections (un-comment if needed)\n",
    "#%pip install tensorflow_datasets\n",
    "#%pip install collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PlantVillage dataset from TFDS instead of the new dataset (it performed data aug on the validation set, which is wrong)\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f20dc-b316-4293-82e4-4c8c9bf7b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of elements per class:\n",
    "class_counts = Counter(tf.argmax(tf.one_hot(label, depth=ds_info.features['label'].num_classes)).numpy() for _, label in ds_train)\n",
    "class_names = ds_info.features['label'].names\n",
    "class_counts_named = {class_names[i]: count for i, count in class_counts.items()}\n",
    "\n",
    "for name, count in class_counts_named.items():\n",
    "    print(f\"{name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the desired number of elements in each class after augmentation (target).\n",
    "#In this run target = # of elements in the largest class \n",
    "target = max(class_counts.values())\n",
    "class_elements = Counter(class_counts)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    # tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.one_hot(label, ds_info.features['label'].num_classes)\n",
    "\n",
    "def preprocess_with_aug(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = data_augmentation(image)  # <-- augment here\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.one_hot(label, ds_info.features['label'].num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beeb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell should apply a class-specific augmentation pipeline before saving the image\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('augmented_data', exist_ok=True)\n",
    "\n",
    "# Create output folders\n",
    "output_root = 'augmented_data'\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(output_root, class_name), exist_ok=True)\n",
    "\n",
    "#Number of elements per class in the new dir:\n",
    "#new_class_elements = Counter(tf.argmax(label).numpy() for _, label in ds_train)\n",
    "new_class_elements = Counter({i: 0 for i in range(len(class_names))})\n",
    "\n",
    "# Augmentation\n",
    "for i, (image, label) in enumerate(ds_train.repeat()):  # .repeat() allows infinite looping\n",
    "    \n",
    "    label_index = label.numpy()\n",
    "    label_name = class_names[label_index]\n",
    "\n",
    "    # Saving the og images in the new empty folders\n",
    "    save_path = os.path.join(output_root, label_name, f'img_{new_class_elements[label_index]}.png')\n",
    "    tf.keras.preprocessing.image.save_img(save_path, image.numpy())\n",
    "    new_class_elements[label_index] += 1\n",
    "\n",
    "\n",
    "    # Stop augmenting if this NEW class is already balanced (= the desired number of images has been saved into this new folder)\n",
    "    if new_class_elements[label_index] >= target:\n",
    "        continue\n",
    "    \n",
    "    # Stop augmenting if this class is already balanced (= the original folder does not require data augmentation, but the new folder is still being filled)\n",
    "    if class_elements[label_index] >= target:\n",
    "        continue\n",
    "\n",
    "    #the two previous lines are the ones that allow the duplication (and eventual augmentation) of the original classes:\n",
    "    #if a class contains a number of images < target, then its images will get duplicated and augmented in the new respective class \n",
    "    #and until the number of elements in that class reaches target\n",
    "    \n",
    "    #if a class contains a number of images >= target, then its images will get duplicated in the new class without \n",
    "    #augmentation until the new class reaches a number of elements = target; in this way if target > max # of elements\n",
    "    # the classes with # of elements > target will be trimmed down in the new dir and will contain less images \n",
    "\n",
    "    \n",
    "    # Apply augmentation\n",
    "    aug_image = data_augmentation(image)\n",
    "\n",
    "    # Save image\n",
    "    save_path = os.path.join(output_root, label_name, f'aug_{new_class_elements[label_index]}.png')\n",
    "    tf.keras.preprocessing.image.save_img(save_path, aug_image.numpy())\n",
    "\n",
    "    # Update count\n",
    "    class_elements[label_index] += 1\n",
    "    new_class_elements[label_index] += 1\n",
    "    \n",
    "\n",
    "    # Stop once all classes are balanced\n",
    "    #if all(class_elements[c] >= target for c in range(num_classes)):\n",
    "    if all(new_class_elements[c] >= target for c in range(num_classes)):\n",
    "        print(\" Classes balanced!! \")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eecd81-1944-4a9a-9e59-d609128bdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful constants\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 64\n",
    "APPLY_DATA_AUGMENTATION = False\n",
    "N_EPOCHS = 30\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes\n",
    "DROP_RATE = 0.3\n",
    "L2_REGULARIZATION = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfcb48-821c-4811-b592-0f7b62a956ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the new training set in the training notebook \n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# Define the path to the augmented data\n",
    "augmented_data_path = os.path.abspath(\"augmented_data\")\n",
    "\n",
    "# Load the dataset from the new directory\n",
    "ds_augmented_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    augmented_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',   # one-hot encoding\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),      # or whatever size your model expects\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Get class names (sorted as image_dataset_from_directory does)\n",
    "class_names = sorted(os.listdir(\"augmented_data\"))\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {cls: len(os.listdir(os.path.join(\"augmented_data\", cls))) for cls in class_names}\n",
    "\n",
    "print(\"Number of images per class:\")\n",
    "for cls in class_names:\n",
    "    print(f\"{cls}: {class_counts[cls]} images\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
