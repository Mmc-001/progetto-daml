{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb560a95",
   "metadata": {},
   "source": [
    "# Progetto d'esame di Data Analysis in Experimental Physics with Machine Learning\n",
    "\n",
    "Gruppo composto dagli studenti Luca Attinà, Sharis Feriotto e Matteo Marchisio Caprioglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32c52",
   "metadata": {},
   "source": [
    "Ipotesi dataset iniziale: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
    "\n",
    "Questo dataset non va bene perchè ha fatto data aug sul validation dataset, fallback al plant village originale: https://www.tensorflow.org/datasets/catalog/plant_village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bab539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import pickle\n",
    "\n",
    "# from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab optional setup\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"Running on Colab:\", IS_COLAB)\n",
    "if IS_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/', force_remount=True)\n",
    "  #Adapt the folder to your specific one where you have downloaded the code\n",
    "  %cd /content/drive/My Drive/path_to/exam-project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ed5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed setting for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da6762d",
   "metadata": {},
   "source": [
    "## Load the PlantVillage dataset from TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:95%]'],\n",
    "    shuffle_files=[True, False],\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# print the number of elements in each dataset\n",
    "print(f\"Number of training images: {ds_info.splits['train[:80%]'].num_examples}\")\n",
    "print(f\"Number of validation images: {ds_info.splits['train[80%:95%]'].num_examples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example from the dataset\n",
    "SAVE_EXAMPLES = False  # Set to True to save the example images\n",
    "fig = tfds.show_examples(ds_train, ds_info, rows=4, cols=4,)\n",
    "if SAVE_EXAMPLES:\n",
    "    fig.savefig('example_images.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only labels (not images) for counting\n",
    "labels_list = []\n",
    "for _, label in ds_train:\n",
    "    labels_list.append(label.numpy())\n",
    "\n",
    "# Convert to pandas Series for fast operations\n",
    "labels_series = pd.Series(labels_list)\n",
    "\n",
    "number_of_classes = ds_info.features['label'].num_classes\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "# Count using pandas (fast) but memory-efficient\n",
    "class_counts = labels_series.value_counts().sort_index()\n",
    "\n",
    "# Print the counts with class names\n",
    "print(\"Number of images per class:\")\n",
    "for idx, count in class_counts.items():\n",
    "    print(f\"{class_names[idx]}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a5686",
   "metadata": {},
   "source": [
    "### Visualize the class distribution in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = False  # Set to True to normalize the counts\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "alphas = np.linspace(1, 0.4, ds_info.features['label'].num_classes)\n",
    "for (name, count, alpha) in zip(class_names, class_counts, alphas):\n",
    "    plt.bar(name, count / (np.sum(class_counts) if NORMALIZE else 1), color='green', alpha=alpha)\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "if NORMALIZE:\n",
    "    plt.ylabel('Normalized #Images per Class')\n",
    "    plt.title('Normalized Class Distribution in PlantVillage Dataset')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Add this line to leave space for the title\n",
    "    plt.savefig('norm_class_distr.png')\n",
    "else:\n",
    "    plt.ylabel('#Images per Class')\n",
    "    plt.title('Class Distribution in PlantVillage Dataset')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Add this line to leave space for the title\n",
    "    plt.savefig('class_distr.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup constants\n",
    "NUM_CLASSES         = ds_info.features['label'].num_classes\n",
    "\n",
    "COMMON_FILENAME = 'base_model'\n",
    "\n",
    "WEIGHTS_DIR = './weights'\n",
    "HISTORY_DIR = './train-hist'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "os.makedirs(HISTORY_DIR, exist_ok=True)\n",
    "CHECKPOINT_FILE = f'{WEIGHTS_DIR}/{COMMON_FILENAME}.h5'\n",
    "HISTORY_FILE = f'{HISTORY_DIR}/history_{COMMON_FILENAME}'\n",
    "\n",
    "IMG_SIZE            = (128, 128) # Image size for resizing in preprocessing\n",
    "IMG_CHANNELS        = 3          # Number of channels in the images (RGB)\n",
    "BATCH_SIZE          = 64         # Batch size for training\n",
    "N_EPOCHS            = 50         # Number of epochs for training\n",
    "STARTING_LR         = 0.0002     # Starting learning rate for the optimizer\n",
    "EARLY_STOP_PATIENCE = 4          # Patience for early stopping\n",
    "REDUCE_LR_PATIENCE  = 3          # Patience for reducing learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b391b",
   "metadata": {},
   "source": [
    "## Preprocess and batch the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "train_ds = ds_train.map(lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = ds_val.map  (lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89253ab",
   "metadata": {},
   "source": [
    "## Build the base architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling\n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a028771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS),\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   drop_rate=0.4,\n",
    "                   ):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Dropout(drop_rate),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_cnn()\n",
    "model.build(input_shape=(None, IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48b97d",
   "metadata": {},
   "source": [
    "## Train the base architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=STARTING_LR)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "n_epochs = N_EPOCHS\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_accuracy',\n",
    "                      patience=EARLY_STOP_PATIENCE,\n",
    "                      restore_best_weights=True,\n",
    "                      verbose=1),\n",
    "        ModelCheckpoint(CHECKPOINT_FILE,\n",
    "                        monitor='val_accuracy', save_best_only=True,\n",
    "                        verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                          factor=0.2, patience=REDUCE_LR_PATIENCE,\n",
    "                          verbose=1,)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf14aa",
   "metadata": {},
   "source": [
    "### Visualize the model training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HISTORY_FILE+'.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_model_history\n",
    "\n",
    "plot_model_history(history)\n",
    "plt.savefig(HISTORY_FILE+'.png', dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3ed73",
   "metadata": {},
   "source": [
    "### For the model evaluation, execute the notebook model_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC AUC for each class (one-vs-rest)\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get true labels and predicted probabilities for the validation set\n",
    "# y_true = []\n",
    "# y_score = []\n",
    "\n",
    "# for images, labels in test_ds:\n",
    "#     y_true.append(labels.numpy())\n",
    "#     y_score.append(model.predict(images))\n",
    "\n",
    "# y_true = np.concatenate(y_true)\n",
    "# y_score = np.concatenate(y_score)\n",
    "\n",
    "# # Compute ROC AUC for each class\n",
    "# n_classes = y_true.shape[1]\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "#     roc_auc[i] = roc_auc_score(y_true[:, i], y_score[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC curve for each class, legend sorted by AUC score\n",
    "# plt.figure(figsize=(12, 12))\n",
    "\n",
    "# # Prepare list of (auc, i) and sort descending\n",
    "# auc_and_idx = sorted([(roc_auc[i], i) for i in range(n_classes)], reverse=True)\n",
    "\n",
    "# for auc, i in auc_and_idx:\n",
    "#     plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {auc:.4f})')\n",
    "# plt.plot([0, 1], [0, 1], 'r--', lw=2, label='Random Classifier')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve - One vs Rest (Validation Set)')\n",
    "# plt.legend(fontsize='small', bbox_to_anchor=(1.05, 1), loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot confusion matrix for the validation set\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # Get true and predicted labels for the validation set\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for images, labels in val_ds:\n",
    "#     y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "#     preds = model.predict(images)\n",
    "#     y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(y_true, y_pred, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a12ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 12))\n",
    "# sns.heatmap(cm, annot=False, fmt='d', cmap='magma', \n",
    "#             xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.ylabel('True label')\n",
    "# plt.title('Confusion Matrix (Validation Set)')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10406a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
