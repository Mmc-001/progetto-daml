{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aaed1-c8f1-4378-a802-a949e502b649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#installation of tensorflow_datasets and Collections (un-comment if needed)\n",
    "#%pip install tensorflow_datasets\n",
    "#%pip install collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PlantVillage dataset from TFDS instead of the new dataset (it performed data aug on the validation set, which is wrong)\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f20dc-b316-4293-82e4-4c8c9bf7b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of elements per class:\n",
    "class_counts = Counter(tf.argmax(label).numpy() for _, label in ds_train)\n",
    "class_names = ds_info.features['label'].names\n",
    "class_counts_named = {class_names[i]: count for i, count in class_counts.items()}\n",
    "\n",
    "for name, count in class_counts_named.items():\n",
    "    print(f\"{name}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the desired number of elements in each class after augmentation (target).\n",
    "#In this run target = # of elements in the largest class \n",
    "target = max(class_counts.values())\n",
    "class_elements = Counter(class_counts)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    # tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.one_hot(label, ds_info.features['label'].num_classes)\n",
    "\n",
    "def preprocess_with_aug(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = data_augmentation(image)  # <-- augment here\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.one_hot(label, ds_info.features['label'].num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beeb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell should apply a class-specific augmentation pipeline before saving the image\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('augmented_data', exist_ok=True)\n",
    "\n",
    "# Create output folders\n",
    "output_root = 'augmented_data'\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(output_root, class_name), exist_ok=True)\n",
    "\n",
    "#Number of elements per class in the new dir:\n",
    "#new_class_elements = Counter(tf.argmax(label).numpy() for _, label in ds_train)\n",
    "new_class_elements = Counter({i: 0 for i in range(len(class_names))})\n",
    "\n",
    "# Augmentation\n",
    "for i, (image, label) in enumerate(ds_train.repeat()):  # .repeat() allows infinite looping\n",
    "    \n",
    "    label_index = tf.argmax(label).numpy()\n",
    "    label_name = class_names[label_index]\n",
    "\n",
    "    # Saving the og images in the new empty folders\n",
    "    save_path = os.path.join(output_root, label_name, f'img_{new_class_elements[label_index]}.png')\n",
    "    tf.keras.preprocessing.image.save_img(save_path, image.numpy())\n",
    "    new_class_elements[label_index] += 1\n",
    "\n",
    "\n",
    "    # Stop augmenting if this NEW class is already balanced (= the desired number of images has been saved into this new folder)\n",
    "    if new_class_elements[label_index] >= target:\n",
    "        continue\n",
    "    \n",
    "    # Stop augmenting if this class is already balanced (= the original folder does not require data augmentation, but the new folder is still being filled)\n",
    "    if class_elements[label_index] >= target:\n",
    "        continue\n",
    "\n",
    "    #the two previous lines are the ones that allow the duplication (and eventual augmentation) of the original classes:\n",
    "    #if a class contains a number of images < target, then its images will get duplicated and augmented in the new respective class \n",
    "    #and until the number of elements in that class reaches target\n",
    "    \n",
    "    #if a class contains a number of images >= target, then its images will get duplicated in the new class without \n",
    "    #augmentation until the new class reaches a number of elements = target; in this way if target > max # of elements\n",
    "    # the classes with # of elements > target will be trimmed down in the new dir and will contain less images \n",
    "\n",
    "    \n",
    "    # Apply augmentation\n",
    "    aug_image = data_augmentation(image)\n",
    "\n",
    "    # Save image\n",
    "    save_path = os.path.join(output_root, label_name, f'aug_{new_class_elements[label_index]}.png')\n",
    "    tf.keras.preprocessing.image.save_img(save_path, aug_image.numpy())\n",
    "\n",
    "    # Update count\n",
    "    class_elements[label_index] += 1\n",
    "    new_class_elements[label_index] += 1\n",
    "    \n",
    "\n",
    "    # Stop once all classes are balanced\n",
    "    #if all(class_elements[c] >= target for c in range(num_classes)):\n",
    "    if all(new_class_elements[c] >= target for c in range(num_classes)):\n",
    "        print(\" Classes balanced!! \")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eecd81-1944-4a9a-9e59-d609128bdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful constants\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 64\n",
    "APPLY_DATA_AUGMENTATION = False\n",
    "N_EPOCHS = 30\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes\n",
    "DROP_RATE = 0.3\n",
    "L2_REGULARIZATION = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfcb48-821c-4811-b592-0f7b62a956ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the new training set in the training notebook\n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# Define the path to the augmented data\n",
    "augmented_data_path = os.path.abspath(\"augmented_data\")\n",
    "\n",
    "# Load the dataset from the new directory\n",
    "ds_augmented_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    augmented_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',   # one-hot encoding\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),      # or whatever size your model expects\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Get class names (sorted as image_dataset_from_directory does)\n",
    "class_names = sorted(os.listdir(\"augmented_data\"))\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {cls: len(os.listdir(os.path.join(\"augmented_data\", cls))) for cls in class_names}\n",
    "\n",
    "print(\"Number of images per class:\")\n",
    "for cls in class_names:\n",
    "    print(f\"{cls}: {class_counts[cls]} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d2930-2f10-41ef-b5e5-b920a3c2e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)  # Or whatever size you're using\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load augmented training data from directory\n",
    "ds_augmented_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    'augmented_data',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',  # or 'int' if you use sparse labels\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=None,  # So we can map first, then batch\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Apply preprocessing and batching\n",
    "train_ds = ds_augmented_train.map(\n",
    "    lambda image, label: preprocess(image, label, None, IMG_SIZE),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Keep validation and test the same (assuming they come from TFDS)\n",
    "val_ds = ds_val.map(\n",
    "    lambda image, label: preprocess(image, label, ds_info, IMG_SIZE),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = ds_test.map(\n",
    "    lambda image, label: preprocess(image, label, ds_info, IMG_SIZE),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee641a-6c28-4de3-8c20-2307924912d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling, Add \n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0c096-1dcb-410a-80ee-ecc9f9fa6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v1(#input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES):\n",
    "    model = Sequential([\n",
    "        \n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "        \n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e8c3c-49ea-47e1-961c-9cb0c7249b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)\n",
    "# optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=n_epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7555755-b21f-4e59-afd4-2ed890d4a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC for each class (one-vs-rest)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get true labels and predicted probabilities for the validation set\n",
    "y_true = []\n",
    "y_score = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    y_true.append(labels.numpy())\n",
    "    y_score.append(model.predict(images))\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_score = np.concatenate(y_score)\n",
    "\n",
    "# Compute ROC AUC for each class\n",
    "n_classes = y_true.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_true[:, i], y_score[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16c042-34ba-4bbe-91bc-495132783f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for the validation set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get true and predicted labels for the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b02559-4121-4492-9aa4-d95d154eb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='magma', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
