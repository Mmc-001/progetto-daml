{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb560a95",
   "metadata": {},
   "source": [
    "# Progetto d'esame di Data Analysis in Experimental Physics with Machine Learning\n",
    "\n",
    "Gruppo composto dagli studenti Luca Attin√†, Sharis Feriotto e Matteo Marchisio Caprioglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32c52",
   "metadata": {},
   "source": [
    "Dataset ipotesi: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prova import dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path + \"/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "val_path = path + \"/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
    "test_path = path + \"/test/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls \"{train_path}\"\n",
    "%ls \"{val_path}\"\n",
    "%ls \"{test_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (128, 128)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_path,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names.sort()\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98514b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipotesi modello\n",
    "# convolutional 2d\n",
    "# relu activation\n",
    "# maxpooling forse?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling\n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def simple_cnn(input_shape=(img_size[0], img_size[1], 3), num_classes=38):\n",
    "    model = Sequential([\n",
    "        Rescaling(1./255, input_shape=input_shape),\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = simple_cnn()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)\n",
    "# optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=n_epochs,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d786741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC for each class (one-vs-rest)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get true labels and predicted probabilities for the validation set\n",
    "y_true = []\n",
    "y_score = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    y_true.append(labels.numpy())\n",
    "    y_score.append(model.predict(images))\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_score = np.concatenate(y_score)\n",
    "\n",
    "# Compute ROC AUC for each class\n",
    "n_classes = y_true.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_true[:, i], y_score[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve for each class, legend sorted by AUC score\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Prepare list of (auc, i) and sort descending\n",
    "auc_and_idx = sorted([(roc_auc[i], i) for i in range(n_classes)], reverse=True)\n",
    "\n",
    "for auc, i in auc_and_idx:\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'r--', lw=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - One vs Rest (Validation Set)')\n",
    "plt.legend(fontsize='small', bbox_to_anchor=(1.05, 1), loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for the validation set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get true and predicted labels for the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a12ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='magma', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19ae98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
