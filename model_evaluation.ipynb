{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "47d454c1",
      "metadata": {
        "id": "47d454c1"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import sys\n",
        "sys.path.append('./src')\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5501855a",
      "metadata": {
        "id": "5501855a",
        "outputId": "1d0ddb90-2bb0-45a8-bded-8cea60002ac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Colab: True\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/progetto-daml\n"
          ]
        }
      ],
      "source": [
        "# Colab optional setup\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "print(\"Running on Colab:\", IS_COLAB)\n",
        "if IS_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/', force_remount=True)\n",
        "  #Adapt the folder to your specific one where you have downloaded the code\n",
        "  %cd /content/drive/My Drive/progetto-daml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9983b827",
      "metadata": {
        "id": "9983b827"
      },
      "source": [
        "# Model Evaluation on PlantVillage Dataset\n",
        "\n",
        "This notebook evaluates the trained model using the test set. It includes metrics, confusion matrix, ROC curves, and a classification report."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3304e7",
      "metadata": {
        "id": "aa3304e7"
      },
      "source": [
        "Be careful if you are running this on COLAB or locally.\n",
        "Due to some bugs, datasets creation is different.\n",
        "Change the lower COLAB bool to True if running on COLAB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "76b37c28",
      "metadata": {
        "id": "76b37c28"
      },
      "outputs": [],
      "source": [
        "COLAB = True  # if True, run on Google Colab, else on local repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bbfcbc46",
      "metadata": {
        "id": "bbfcbc46"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "14439c4c",
      "metadata": {
        "id": "14439c4c"
      },
      "outputs": [],
      "source": [
        "#define prerpocess function\n",
        "def preprocess(image, label, image_size=(128, 128)):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563717d4",
      "metadata": {
        "id": "563717d4"
      },
      "source": [
        "IF RUNNING ON COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "486d1346",
      "metadata": {
        "id": "486d1346"
      },
      "outputs": [],
      "source": [
        "if COLAB: #if running on colab\n",
        "    ds_info = tfds.builder('plant_village').info\n",
        "    ds_test = tfds.load('plant_village', split='train[95%:]', as_supervised=True)\n",
        "\n",
        "    class_names = ds_info.features['label'].names\n",
        "    families = sorted({n.split('___')[0] for n in class_names})\n",
        "    split_labels = families\n",
        "    family_map = tf.constant([families.index(n.split('___')[0]) for n in class_names], dtype=tf.int32)\n",
        "\n",
        "    # returns label as one-hot\n",
        "    def to_ohe(img, lbl):\n",
        "      idx = tf.gather(family_map, lbl)\n",
        "      return img, tf.one_hot(idx, len(split_labels))\n",
        "\n",
        "    test_ds  = ds_test.map(to_ohe)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0dcc80b",
      "metadata": {
        "id": "a0dcc80b"
      },
      "source": [
        "IF RUNNING ON LOCAL REPOSITORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "d7a6b29d",
      "metadata": {
        "id": "d7a6b29d"
      },
      "outputs": [],
      "source": [
        "# Define local path to generate split\n",
        "if not COLAB:\n",
        "    from pathlib import Path\n",
        "    from preprocessing import preprocess\n",
        "\n",
        "    base_path = Path(r\"D:\\progetto-daml\") #Change according to the path where PlantVillage-Dataset is cloned. Same as training notebook\n",
        "    base_path = base_path / \"PlantVillage-Dataset\"\n",
        "\n",
        "    OUTPUT_ROOT = base_path / \"by_family\" # 14 families splitting\n",
        "\n",
        "    # read test set\n",
        "    split_labels = sorted([p.name for p in (OUTPUT_ROOT/\"train\").iterdir() if p.is_dir()]) #folders names\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        str(OUTPUT_ROOT/\"test\"),\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='categorical',\n",
        "        shuffle=False,\n",
        "    )\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22471a73",
      "metadata": {
        "id": "22471a73"
      },
      "source": [
        "# Model selection and test evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "36daf8c8",
      "metadata": {
        "id": "36daf8c8",
        "outputId": "77fed25e-a123-448f-b52a-de3b87403f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file name: best_model_14_families_categorical_l2coeff_1e-3.h5\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    0: \"best_model_basecnn_14_families.h5\", # run with import from directory\n",
        "    1: \"best_model_14_families_categorical_l2coeff_1e-3.h5\", # run with import from directory\n",
        "    2: \"best_model_14_families_focal_l2coeff_1e-3.h5\", # run with import from directory\n",
        "    3: \"best_model_14_families_transfer_mobilenet.h5\" # run with import through tfds.load\n",
        "}\n",
        "\n",
        "# model selection through index (if you change model, please recompile from preprocess function)\n",
        "n = 1\n",
        "\n",
        "model_name = models.get(n)\n",
        "if model_name is None:\n",
        "    print(f\"No file associated to {n}\")\n",
        "else:\n",
        "    model_path = f\"./weights/{model_name}\"\n",
        "    print(f\"Model file name: {model_name}\")\n",
        "\n",
        "#comment following line if you have trained and saved new files after Sunday 27/07, 9 PM\n",
        "if n != 3 and not COLAB:\n",
        "    test_ds = test_ds.map(lambda img, lbl: (tf.image.resize(img, IMG_SIZE), lbl)).prefetch(tf.data.AUTOTUNE)\n",
        "if n != 3 and COLAB:\n",
        "    test_ds = test_ds.map(lambda img, lbl: (tf.image.resize(img, IMG_SIZE), lbl)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "if n == 3 and COLAB:\n",
        "    test_ds = test_ds.map(lambda img, lbl: preprocess(img, lbl, IMG_SIZE)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "if n == 3 and not COLAB:\n",
        "    test_ds = test_ds.map(lambda img, lbl: preprocess(img, lbl, IMG_SIZE)).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "859e5dbe",
      "metadata": {
        "id": "859e5dbe",
        "outputId": "899fa3db-f1f6-48ff-a9d9-3ebef7980c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load Trained Model and Test Data\n",
        "model = keras.models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "8aebc1a4",
      "metadata": {
        "id": "8aebc1a4",
        "outputId": "067b59b2-7aa7-4b04-a0f8-1c7e69e855b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n"
          ]
        }
      ],
      "source": [
        "# Generate Predictions on Test Set\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_score = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    preds = model.predict(images)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "    y_score.append(preds)\n",
        "y_score = np.concatenate(y_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "cb1b801e",
      "metadata": {
        "id": "cb1b801e",
        "outputId": "6b4949a2-fabb-41a4-8e19-b6fcaa8bd8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.990424\n",
            "Precision: 0.990500\n",
            "Recall: 0.990424\n",
            "F1-score: 0.990421\n"
          ]
        }
      ],
      "source": [
        "# Calculate Evaluation Metrics (Accuracy, Precision, Recall, F1)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Precision: {precision:.6f}\")\n",
        "print(f\"Recall: {recall:.6f}\")\n",
        "print(f\"F1-score: {f1:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6cf9aa",
      "metadata": {
        "id": "db6cf9aa"
      },
      "outputs": [],
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "from plotting import plot_confusion_matrix\n",
        "\n",
        "plt.figure()  # Set a larger figure size for better readability\n",
        "plot_confusion_matrix(\n",
        "    np.array(y_true),\n",
        "    np.array(y_pred),\n",
        "    classes=split_labels,\n",
        "    normalize=True,\n",
        "    title=\"Confusion Matrix (Test Set)\",\n",
        "    cmap=\"plasma\"\n",
        ")\n",
        "plt.tight_layout()  # Ensure labels and ticks are not cut off\n",
        "plt.savefig(f'./conf-matrix/confusion_matrix_v{model_name}.png', dpi=400, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78653ade",
      "metadata": {
        "id": "78653ade"
      },
      "outputs": [],
      "source": [
        "# Plot ROC Curves for Each Class\n",
        "n_classes = y_score.shape[1]\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(np.eye(n_classes)[y_true][:, i], y_score[:, i])\n",
        "    roc_auc[i] = roc_auc_score(np.eye(n_classes)[y_true][:, i], y_score[:, i])\n",
        "plt.figure(figsize=(12, 12))\n",
        "auc_and_idx = sorted([(roc_auc[i], i) for i in range(n_classes)], reverse=True)\n",
        "for auc, i in auc_and_idx:\n",
        "    plt.plot(fpr[i], tpr[i], label=f'{split_labels[i]} (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'r--', lw=2, label='Random Classifier (AUC = 0.5)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - One vs Rest (Test Set)')\n",
        "plt.legend(fontsize='small', bbox_to_anchor=(1.05, 1), loc='best')\n",
        "plt.savefig(f'./roc-curves/roc_curve_v{model_name}.png', dpi=400, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ca07de",
      "metadata": {
        "id": "d1ca07de"
      },
      "outputs": [],
      "source": [
        "# Display Classification Report\n",
        "report = classification_report(y_true, y_pred, target_names=split_labels)\n",
        "print(report)\n",
        "\n",
        "# Save the classification report to a text file\n",
        "with open(f'./reports/report_v{model_name}.txt', 'w') as f:\n",
        "    f.write(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa188ccc",
      "metadata": {
        "id": "fa188ccc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}