{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb560a95",
   "metadata": {},
   "source": [
    "# Progetto d'esame di Data Analysis in Experimental Physics with Machine Learning\n",
    "Gruppo composto dagli studenti Luca Attinà, Sharis Feriotto e Matteo Marchisio Caprioglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32c52",
   "metadata": {},
   "source": [
    "Dataset ipotesi: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
    "\n",
    "Questo dataset non va bene perchè ha fatto data aug sul validation dataset, fallback al plant village originale: https://www.tensorflow.org/datasets/catalog/plant_village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import pickle\n",
    "\n",
    "# from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed setting for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd18470",
   "metadata": {},
   "source": [
    "## Load the PlantVillage dataset from TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:95%]', 'train[95%:]'],\n",
    "    # shuffle_files=True,\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example from the dataset\n",
    "tfds.show_examples(ds_train, ds_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7222498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only labels (not images) for counting\n",
    "labels_list = []\n",
    "for _, label in ds_train:\n",
    "    labels_list.append(label.numpy())\n",
    "\n",
    "# Convert to pandas Series for fast operations\n",
    "labels_series = pd.Series(labels_list)\n",
    "\n",
    "number_of_classes = ds_info.features['label'].num_classes\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "# Count using pandas (fast) but memory-efficient\n",
    "class_counts = labels_series.value_counts().sort_index()\n",
    "\n",
    "# Print the counts with class names\n",
    "print(\"Number of images per class:\")\n",
    "for idx, count in class_counts.items():\n",
    "    print(f\"{class_names[idx]}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_names, class_counts, color='skyblue')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution in PlantVillage Dataset')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup constants\n",
    "NUM_CLASSES         = ds_info.features['label'].num_classes\n",
    "ARCH_CHOICE         = 0 # 0: simple_cnn_v0, 1: simple_cnn_v1, 2: simple_cnn_v2\n",
    "WEIGHTS_DIR = './weights'\n",
    "HISTORY_DIR = './train-hist'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "os.makedirs(HISTORY_DIR, exist_ok=True)\n",
    "CHECKPOINT_FILE = f'{WEIGHTS_DIR}/best_model_v{ARCH_CHOICE}.h5'\n",
    "HISTORY_FILE = f'{HISTORY_DIR}/history_v{ARCH_CHOICE}'\n",
    "\n",
    "IMG_SIZE            = (128, 128) # Image size for resizing in preprocessing\n",
    "IMG_CHANNELS        = 3          # Number of channels in the images (RGB)\n",
    "BATCH_SIZE          = 64         # Batch size for training\n",
    "N_EPOCHS            = 50         # Number of epochs for training\n",
    "STARTING_LR         = 0.0002     # Starting learning rate for the optimizer\n",
    "EARLY_STOP_PATIENCE = 4          # Patience for early stopping\n",
    "REDUCE_LR_PATIENCE  = 3          # Patience for reducing learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cd3c7",
   "metadata": {},
   "source": [
    "## Preprocess and batch the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "train_ds = ds_train.map(lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = ds_val.map  (lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = ds_test.map (lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f78cd",
   "metadata": {},
   "source": [
    "## Build the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling, Add \n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v0(input_shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS),\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   drop_rate=0.4,\n",
    "                #    l2_reg=0.005,\n",
    "                   ):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Dropout(drop_rate),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v1(input_shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS),\n",
    "                  num_classes=NUM_CLASSES,\n",
    "                  drop_rate=0.4,\n",
    "                  #l2_reg=0.005,\n",
    "                   ):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), padding='same', input_shape=input_shape),\n",
    "        Activation('relu'),\n",
    "        Dropout(drop_rate),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(32, (3, 3), padding='same'),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(64, (3, 3), padding='same'),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v2(input_shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS),\n",
    "                  num_classes=NUM_CLASSES,\n",
    "                  drop_rate=0.4,\n",
    "                  l2_reg=0.01,\n",
    "                  ):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), input_shape=input_shape),\n",
    "        Activation('relu'),\n",
    "        Dropout(drop_rate),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_reg))\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [simple_cnn_v0,\n",
    "               simple_cnn_v1,\n",
    "               simple_cnn_v2,\n",
    "               ]\n",
    "if ARCH_CHOICE not in range(0, len(models_list) + 1):\n",
    "    raise ValueError(\"Invalid architecture choice\")\n",
    "else:\n",
    "    model = models_list[ARCH_CHOICE]()\n",
    "\n",
    "model.build(input_shape=(None, IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS))  # Build the model with dynamic batch size\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    # loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    # loss=tf.keras.losses.CategoricalFocalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f1009",
   "metadata": {},
   "source": [
    "### Calculate class weights for weighted training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a31e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Get all labels from the training set\n",
    "labels = []\n",
    "for _, label in ds_train:\n",
    "    labels.append(label.numpy())\n",
    "labels = np.array(labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940fa98",
   "metadata": {},
   "source": [
    "## Train the selected architecture\n",
    "Or just visualize the training history of an already-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5de7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True  # Change to False to only visualize an already trained model's history\n",
    "\n",
    "if TRAIN:\n",
    "    # Train the model\n",
    "    print(f\"Training the model v{ARCH_CHOICE}...\")\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_accuracy',\n",
    "                    #   min_delta=0.005,\n",
    "                      patience=EARLY_STOP_PATIENCE,\n",
    "                      restore_best_weights=True,\n",
    "                      verbose=1),\n",
    "        ModelCheckpoint(CHECKPOINT_FILE,\n",
    "                        # min_delta=0.005,\n",
    "                        monitor='val_accuracy',\n",
    "                        save_best_only=True,\n",
    "                        verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                        #   min_delta=0.005,\n",
    "                          factor=0.2,\n",
    "                          patience=REDUCE_LR_PATIENCE,\n",
    "                          verbose=1)\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    )\n",
    "    # Save history after training\n",
    "    with open(HISTORY_FILE+'.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "else:\n",
    "    # Load history if not training\n",
    "    with open(HISTORY_FILE+'.pkl', 'rb') as f:\n",
    "        loaded_history = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy class to mimic Keras History for plotting\n",
    "class DummyHistory:\n",
    "    def __init__(self, history_dict):\n",
    "        self.history = history_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bbd110",
   "metadata": {},
   "source": [
    "### Visualize the model training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c142fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_model_history\n",
    "if not TRAIN:\n",
    "    history = DummyHistory(loaded_history)\n",
    "else:\n",
    "    pass\n",
    "plot_model_history(history)\n",
    "plt.savefig(HISTORY_FILE+'.png', dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabe701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
