{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb560a95",
   "metadata": {},
   "source": [
    "# Progetto d'esame di Data Analysis in Experimental Physics with Machine Learning\n",
    "Gruppo composto dagli studenti Luca Attinà, Sharis Feriotto e Matteo Marchisio Caprioglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32c52",
   "metadata": {},
   "source": [
    "Dataset ipotesi: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
    "\n",
    "Questo dataset non va bene perchè ha fatto data aug sul validation dataset, fallback al plant village originale: https://www.tensorflow.org/datasets/catalog/plant_village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed setting for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PlantVillage dataset from TFDS instead of the new dataset (it performed data aug on the validation set, which is wrong)\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:95%]', 'train[95%:]'],\n",
    "    # shuffle_files=True,\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example from the dataset\n",
    "tfds.show_examples(ds_train, ds_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e72308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training dataset to a DataFrame\n",
    "df = tfds.as_dataframe(ds_train, ds_info)\n",
    "\n",
    "number_of_classes = ds_info.features['label'].num_classes\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = df['label'].value_counts().sort_index()\n",
    "\n",
    "# Print the counts with class names\n",
    "print(\"Number of images per class:\")\n",
    "for idx, count in class_counts.items():\n",
    "    print(f\"{class_names[idx]}: {count} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful constants\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 64\n",
    "APPLY_DATA_AUGMENTATION = False\n",
    "N_EPOCHS = 30\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes\n",
    "DROP_RATE = 0.3\n",
    "L2_REGULARIZATION = 0.005\n",
    "TRAIN = True # Change to False to only visualize an already trained model's history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and batch the datasets\n",
    "from preprocessing import preprocess\n",
    "\n",
    "train_ds = ds_train.map(lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = ds_val.map  (lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = ds_test.map (lambda image, label: preprocess(image, label, ds_info, IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling, Add \n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b31932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v1(#input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES):\n",
    "    model = Sequential([\n",
    "        \n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "        \n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d93c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v2(#input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES):\n",
    "    model = Sequential([\n",
    "        \n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "        \n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        Conv2D(64, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        # Flatten(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        Dropout(DROP_RATE),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v3(#input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES):\n",
    "    model = Sequential([\n",
    "        \n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "        \n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        Conv2D(64, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        Conv2D(128, (5, 5), padding='same', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(DROP_RATE),\n",
    "\n",
    "        # Flatten(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(L2_REGULARIZATION)),\n",
    "        Dropout(DROP_RATE),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_resnet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=NUM_CLASSES):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First block\n",
    "    x = Conv2D(16, (3, 3), padding='same', kernel_regularizer=l2(L2_REGULARIZATION))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(DROP_RATE)(x)\n",
    "    \n",
    "    # Second block with skip connection\n",
    "    shortcut = Conv2D(32, (1, 1), strides=2, padding='same')(x)  # Match shape\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(L2_REGULARIZATION))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(DROP_RATE)(x)\n",
    "    x = Add()([x, shortcut])  # Skip connection\n",
    "    \n",
    "    # Third block\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(L2_REGULARIZATION))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(DROP_RATE)(x)\n",
    "    \n",
    "    # Global pooling and output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(L2_REGULARIZATION))(x)\n",
    "    x = Dropout(DROP_RATE)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_choice = 1  # Choose the architecture version\n",
    "if arch_choice == 1:\n",
    "    model = simple_cnn_v1()\n",
    "elif arch_choice == 2:\n",
    "    model = simple_cnn_v2()\n",
    "elif arch_choice == 3:\n",
    "    model = simple_cnn_v3()\n",
    "elif arch_choice == 4:\n",
    "    model = simple_resnet()\n",
    "else:\n",
    "    raise ValueError(\"Invalid architecture choice\")\n",
    "\n",
    "model.build(input_shape=(None, IMG_SIZE[0], IMG_SIZE[1], 3))  # Build the model with dynamic batch size\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)\n",
    "# optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "check_point_filename = f'best_model_v{arch_choice}.h5'  # Checkpoint filename for different architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a31e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Get all labels from the training set\n",
    "labels = []\n",
    "for _, label in ds_train:\n",
    "    labels.append(label.numpy())\n",
    "labels = np.array(labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5de7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if TRAIN:\n",
    "    # Train the model\n",
    "    print(f\"Training the model v{arch_choice}...\")\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),\n",
    "        ModelCheckpoint(check_point_filename, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    )\n",
    "    # Save history after training\n",
    "    with open(f'./train-hist/history_v{arch_choice}.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "else:\n",
    "    # Load history if not training\n",
    "    with open(f'./train-hist/history_v{arch_choice}.pkl', 'rb') as f:\n",
    "        loaded_history = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy class to mimic Keras History for plotting\n",
    "class DummyHistory:\n",
    "    def __init__(self, history_dict):\n",
    "        self.history = history_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c142fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_model_history\n",
    "if TRAIN:\n",
    "    pass\n",
    "else:\n",
    "    history = DummyHistory(loaded_history)\n",
    "plot_model_history(history)\n",
    "plt.savefig(f'./train-hist/history_v{arch_choice}.png', dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8049e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
