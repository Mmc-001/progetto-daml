{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb560a95",
   "metadata": {},
   "source": [
    "# Progetto d'esame di Data Analysis in Experimental Physics with Machine Learning\n",
    "Gruppo composto dagli studenti Luca Attinà, Sharis Feriotto e Matteo Marchisio Caprioglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf32c52",
   "metadata": {},
   "source": [
    "Dataset ipotesi: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
    "\n",
    "Questo dataset non va bene perchè ha fatto data aug sul validation dataset, fallback al plant village originale: https://www.tensorflow.org/datasets/catalog/plant_village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed setting for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PlantVillage dataset from TFDS instead of the new dataset (it performed data aug on the validation set, which is wrong)\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:95%]', 'train[95%:]'],\n",
    "    # shuffle_files=True,\n",
    "    as_supervised=True,  # returns (image, label) pairs\n",
    "    with_info=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example from the dataset\n",
    "tfds.show_examples(ds_train, ds_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7222498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only labels (not images) for counting\n",
    "labels_list = []\n",
    "for _, label in ds_train:\n",
    "    labels_list.append(label.numpy())\n",
    "\n",
    "# Convert to pandas Series for fast operations\n",
    "labels_series = pd.Series(labels_list)\n",
    "\n",
    "number_of_classes = ds_info.features['label'].num_classes\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "# Count using pandas (fast) but memory-efficient\n",
    "class_counts = labels_series.value_counts().sort_index()\n",
    "\n",
    "# Print the counts with class names\n",
    "print(\"Number of images per class:\")\n",
    "for idx, count in class_counts.items():\n",
    "    print(f\"{class_names[idx]}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_names, class_counts, color='skyblue')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution in PlantVillage Dataset')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_par as cfp # setup constants\n",
    "NUM_CLASSES         = ds_info.features['label'].num_classes\n",
    "ARCH_CHOICE        = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and batch the datasets\n",
    "from preprocessing import preprocess\n",
    "\n",
    "train_ds = ds_train.map(lambda image, label: preprocess(image, label, ds_info, cfp.IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(cfp.BATCH_SIZE[ARCH_CHOICE]).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = ds_val.map  (lambda image, label: preprocess(image, label, ds_info, cfp.IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(cfp.BATCH_SIZE[ARCH_CHOICE]).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = ds_test.map (lambda image, label: preprocess(image, label, ds_info, cfp.IMG_SIZE), num_parallel_calls=tf.data.AUTOTUNE).batch(cfp.BATCH_SIZE[ARCH_CHOICE]).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, BatchNormalization, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, ReLU, Rescaling, Add \n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v0(#input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   drop_rate=cfp.DROP_RATE[0],\n",
    "                #    l2_reg=cfp.L2_REGULARIZATION[0],\n",
    "                   ):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        Dropout(drop_rate),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b31932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v1(#input_shape=(cfp.IMG_SIZE[0], cfp.IMG_SIZE[1], 3),\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   drop_rate=cfp.DROP_RATE[1],\n",
    "                   l2_reg=cfp.L2_REGULARIZATION[1]):\n",
    "    model = Sequential([\n",
    "\n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        # Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d93c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v2(#input_shape=(cfp.IMG_SIZE[0], cfp.IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES,\n",
    "                drop_rate=cfp.DROP_RATE[2],\n",
    "                l2_reg=cfp.L2_REGULARIZATION[2]):\n",
    "    model = Sequential([\n",
    "\n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(64, (5, 5), padding='same', kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        # Flatten(),\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "        Dropout(drop_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn_v3(#input_shape=(cfp.IMG_SIZE[0], cfp.IMG_SIZE[1], 3),\n",
    "                num_classes=NUM_CLASSES,\n",
    "                drop_rate=cfp.DROP_RATE[3],\n",
    "                l2_regularization=cfp.L2_REGULARIZATION[3]):\n",
    "    model = Sequential([\n",
    "\n",
    "        Conv2D(16, (5, 5), padding='same', kernel_regularizer=l2(l2_regularization)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(32, (5, 5), padding='same', kernel_regularizer=l2(l2_regularization)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(64, (5, 5), padding='same', kernel_regularizer=l2(l2_regularization)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        Conv2D(128, (5, 5), padding='same', kernel_regularizer=l2(l2_regularization)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop_rate),\n",
    "\n",
    "        # Flatten(),\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(l2_regularization)),\n",
    "        Dropout(drop_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_resnet(input_shape=(cfp.IMG_SIZE[0], cfp.IMG_SIZE[1], 3), \n",
    "                  num_classes=NUM_CLASSES,\n",
    "                  drop_rate=cfp.DROP_RATE[4],\n",
    "                  l2_reg=cfp.L2_REGULARIZATION[4]):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First block\n",
    "    shortcut_1 = Conv2D(16, (1, 1), strides=2, padding='same')(inputs)  # Match shape\n",
    "    x = Conv2D(16, (3, 3), padding='same', kernel_regularizer=l2(l2_reg))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(drop_rate)(x)\n",
    "    x = Add()([x, shortcut_1])  # Skip connection\n",
    "\n",
    "    # Second block with skip connection\n",
    "    shortcut_2 = Conv2D(32, (1, 1), strides=2, padding='same')(x)  # Match shape\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(drop_rate)(x)\n",
    "    x = Add()([x, shortcut_2])  # Skip connection\n",
    "    \n",
    "    # Third block\n",
    "    shortcut_3 = Conv2D(64, (1, 1), strides=2, padding='same')(x)  # Match shape\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(drop_rate)(x)\n",
    "    x = Add()([x, shortcut_3])  # Skip connection\n",
    "\n",
    "    # Global pooling and output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x = Dropout(drop_rate)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [simple_cnn_v0, simple_cnn_v1, simple_cnn_v2, simple_cnn_v3, simple_resnet]\n",
    "if ARCH_CHOICE not in range(0, len(models_list) + 1):\n",
    "    raise ValueError(\"Invalid architecture choice\")\n",
    "else:\n",
    "    model = models_list[ARCH_CHOICE]()\n",
    "\n",
    "model.build(input_shape=(None, cfp.IMG_SIZE[0], cfp.IMG_SIZE[1], 3))  # Build the model with dynamic batch size\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)\n",
    "# optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "check_point_filename = f'./weights/best_model_v{ARCH_CHOICE}.h5'  # Checkpoint filename for different architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a31e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Get all labels from the training set\n",
    "labels = []\n",
    "for _, label in ds_train:\n",
    "    labels.append(label.numpy())\n",
    "labels = np.array(labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5de7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "TRAIN = True  # Change to False to only visualize an already trained model's history\n",
    "\n",
    "if TRAIN:\n",
    "    # Train the model\n",
    "    print(f\"Training the model v{ARCH_CHOICE}...\")\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfp.N_EPOCHS[ARCH_CHOICE],\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss',\n",
    "                      patience=cfp.EARLY_PATIENCE[ARCH_CHOICE],\n",
    "                      restore_best_weights=True,\n",
    "                      verbose=1),\n",
    "        ModelCheckpoint(check_point_filename,\n",
    "                        monitor='val_loss',\n",
    "                        save_best_only=True,\n",
    "                        verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss',\n",
    "                          factor=0.1,\n",
    "                          patience=cfp.REDUCE_LR_PATIENCE[ARCH_CHOICE],\n",
    "                          verbose=1)\n",
    "    ],\n",
    "    class_weight=class_weights_dict,\n",
    "    )\n",
    "    # Save history after training\n",
    "    with open(f'./train-hist/history_v{ARCH_CHOICE}.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "else:\n",
    "    # Load history if not training\n",
    "    with open(f'./train-hist/history_v{ARCH_CHOICE}.pkl', 'rb') as f:\n",
    "        loaded_history = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy class to mimic Keras History for plotting\n",
    "class DummyHistory:\n",
    "    def __init__(self, history_dict):\n",
    "        self.history = history_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c142fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_model_history\n",
    "if not TRAIN:\n",
    "    history = DummyHistory(loaded_history)\n",
    "else:\n",
    "    pass\n",
    "plot_model_history(history)\n",
    "plt.savefig(f'./train-hist/history_v{ARCH_CHOICE}.png', dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabe701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
